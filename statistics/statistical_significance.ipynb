{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40b15b96-b191-4a64-8907-c9a97bee892d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Performance Metrics:\n",
      "           Metric     XGBoost          PR          ANN\n",
      "0             mae    5.040339   11.521451     2.329645\n",
      "1             mse   117.14172  296.260161    51.903281\n",
      "2            rmse   10.823188   17.211468     7.201981\n",
      "3              r2    0.873095    0.679392     0.943831\n",
      "4   training_time  6098.33079  532.226326  4722.174172\n",
      "5  inference_time    8.200664    9.572506     6.651212\n",
      "\n",
      "Nemenyi post-hoc test results for mae:\n",
      "          XGBoost        PR       ANN\n",
      "XGBoost  1.000000  0.254114  0.254114\n",
      "PR       0.254114  1.000000  0.004467\n",
      "ANN      0.254114  0.004467  1.000000\n",
      "\n",
      "Nemenyi post-hoc test results for mse:\n",
      "          XGBoost        PR       ANN\n",
      "XGBoost  1.000000  0.254114  0.254114\n",
      "PR       0.254114  1.000000  0.004467\n",
      "ANN      0.254114  0.004467  1.000000\n",
      "\n",
      "Nemenyi post-hoc test results for rmse:\n",
      "          XGBoost        PR       ANN\n",
      "XGBoost  1.000000  0.254114  0.254114\n",
      "PR       0.254114  1.000000  0.004467\n",
      "ANN      0.254114  0.004467  1.000000\n",
      "\n",
      "Nemenyi post-hoc test results for r2:\n",
      "          XGBoost        PR       ANN\n",
      "XGBoost  1.000000  0.254114  0.254114\n",
      "PR       0.254114  1.000000  0.004467\n",
      "ANN      0.254114  0.004467  1.000000\n",
      "\n",
      "Nemenyi post-hoc test results for training_time:\n",
      "          XGBoost        PR       ANN\n",
      "XGBoost  1.000000  0.012315  0.600820\n",
      "PR       0.012315  1.000000  0.139445\n",
      "ANN      0.600820  0.139445  1.000000\n",
      "\n",
      "Friedman Test Results:\n",
      "           Metric  Statistic   p-value\n",
      "0             mae       10.0  0.006738\n",
      "1             mse       10.0  0.006738\n",
      "2            rmse       10.0  0.006738\n",
      "3              r2       10.0  0.006738\n",
      "4   training_time        8.4  0.014996\n",
      "5  inference_time        4.8  0.090718\n",
      "\n",
      "Pairwise Wilcoxon Signed-Rank Test Results:\n",
      "            Metric      Comparison  Statistic  p-value\n",
      "0              mae   XGBoost vs PR        0.0   0.0625\n",
      "1              mae  XGBoost vs ANN        0.0   0.0625\n",
      "2              mae       PR vs ANN        0.0   0.0625\n",
      "3              mse   XGBoost vs PR        0.0   0.0625\n",
      "4              mse  XGBoost vs ANN        0.0   0.0625\n",
      "5              mse       PR vs ANN        0.0   0.0625\n",
      "6             rmse   XGBoost vs PR        0.0   0.0625\n",
      "7             rmse  XGBoost vs ANN        0.0   0.0625\n",
      "8             rmse       PR vs ANN        0.0   0.0625\n",
      "9               r2   XGBoost vs PR        0.0   0.0625\n",
      "10              r2  XGBoost vs ANN        0.0   0.0625\n",
      "11              r2       PR vs ANN        0.0   0.0625\n",
      "12   training_time   XGBoost vs PR        0.0   0.0625\n",
      "13   training_time  XGBoost vs ANN        2.0   0.1875\n",
      "14   training_time       PR vs ANN        0.0   0.0625\n",
      "15  inference_time   XGBoost vs PR        5.0   0.6250\n",
      "16  inference_time  XGBoost vs ANN        0.0   0.0625\n",
      "17  inference_time       PR vs ANN        2.0   0.1875\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import friedmanchisquare, wilcoxon\n",
    "import scikit_posthocs as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Step 1: Read the CSV files\n",
    "xgboost_df = pd.read_csv('21.csv')\n",
    "pr_df = pd.read_csv('4_degree.csv')\n",
    "ann_df = pd.read_csv('metrics_128_units.csv')\n",
    "\n",
    "# Step 2: Extract the performance metrics for the folds (excluding mean, std, sum)\n",
    "xgboost_folds = xgboost_df.iloc[0:5].reset_index(drop=True)\n",
    "pr_folds = pr_df.iloc[0:5].reset_index(drop=True)\n",
    "ann_folds = ann_df.iloc[0:5].reset_index(drop=True)\n",
    "\n",
    "# Define the list of metrics to analyze\n",
    "metrics = ['mae', 'mse', 'rmse', 'r2', 'training_time', 'inference_time']\n",
    "\n",
    "# Ensure that the metrics columns exist in all DataFrames\n",
    "for df in [xgboost_df, pr_df, ann_df]:\n",
    "    missing_metrics = set(metrics) - set(df.columns)\n",
    "    if missing_metrics:\n",
    "        print(f\"Error: Missing columns {missing_metrics} in DataFrame.\")\n",
    "        exit()\n",
    "\n",
    "# Step 3: Create a DataFrame for mean performance metrics\n",
    "mean_metrics_df = pd.DataFrame({\n",
    "    'Metric': metrics,\n",
    "    'XGBoost': xgboost_df.iloc[5][metrics].values,\n",
    "    'PR': pr_df.iloc[5][metrics].values,\n",
    "    'ANN': ann_df.iloc[5][metrics].values\n",
    "})\n",
    "\n",
    "print('Mean Performance Metrics:')\n",
    "print(mean_metrics_df)\n",
    "\n",
    "# Save the mean_metrics DataFrame to a CSV file\n",
    "mean_metrics_df.to_csv('mean_performance_metrics.csv', index=False)\n",
    "\n",
    "# Step 4: Perform statistical tests for each metric\n",
    "# Initialize a list to store Friedman test results\n",
    "friedman_results = []\n",
    "\n",
    "# Initialize a list to store pairwise Wilcoxon test results\n",
    "pairwise_results_list = []\n",
    "\n",
    "for metric in metrics:\n",
    "    # Prepare data for the current metric\n",
    "    data = pd.DataFrame({\n",
    "        'XGBoost': xgboost_folds[metric],\n",
    "        'PR': pr_folds[metric],\n",
    "        'ANN': ann_folds[metric]\n",
    "    })\n",
    "    \n",
    "    # Check if all values are numeric\n",
    "    if not np.issubdtype(data['XGBoost'].dtype, np.number) or \\\n",
    "       not np.issubdtype(data['PR'].dtype, np.number) or \\\n",
    "       not np.issubdtype(data['ANN'].dtype, np.number):\n",
    "        print(f\"Error: Non-numeric data found in metric '{metric}'.\")\n",
    "        continue  # Skip this metric\n",
    "    \n",
    "    # Perform the Friedman test\n",
    "    statistic, p_value = friedmanchisquare(data['XGBoost'], data['PR'], data['ANN'])\n",
    "    friedman_results.append({'Metric': metric, 'Statistic': statistic, 'p-value': p_value})\n",
    "    \n",
    "    # Perform Nemenyi post-hoc test if Friedman test is significant\n",
    "    if p_value < 0.05:\n",
    "        nemenyi_result = sp.posthoc_nemenyi_friedman(data.values)\n",
    "        nemenyi_result.columns = ['XGBoost', 'PR', 'ANN']\n",
    "        nemenyi_result.index = ['XGBoost', 'PR', 'ANN']\n",
    "        print(f'\\nNemenyi post-hoc test results for {metric}:')\n",
    "        print(nemenyi_result)\n",
    "    \n",
    "    # Perform pairwise Wilcoxon signed-rank tests\n",
    "    pairs = [('XGBoost', 'PR'), ('XGBoost', 'ANN'), ('PR', 'ANN')]\n",
    "    for model1, model2 in pairs:\n",
    "        # Calculate differences to check for zero variance\n",
    "        differences = data[model1] - data[model2]\n",
    "        if np.all(differences == 0):\n",
    "            stat = 0.0\n",
    "            p = 1.0\n",
    "        else:\n",
    "            # Use zero_method='pratt' to handle zero differences\n",
    "            stat, p = wilcoxon(data[model1], data[model2], zero_method='pratt')\n",
    "        pairwise_results_list.append({\n",
    "            'Metric': metric,\n",
    "            'Comparison': f'{model1} vs {model2}',\n",
    "            'Statistic': stat,\n",
    "            'p-value': p\n",
    "        })\n",
    "\n",
    "# Create DataFrame for Friedman test results\n",
    "friedman_results_df = pd.DataFrame(friedman_results)\n",
    "\n",
    "print('\\nFriedman Test Results:')\n",
    "print(friedman_results_df)\n",
    "\n",
    "# Create DataFrame for pairwise Wilcoxon test results\n",
    "pairwise_results_df = pd.DataFrame(pairwise_results_list)\n",
    "\n",
    "print('\\nPairwise Wilcoxon Signed-Rank Test Results:')\n",
    "print(pairwise_results_df)\n",
    "\n",
    "# Save the DataFrames to CSV files\n",
    "friedman_results_df.to_csv('friedman_test_results.csv', index=False)\n",
    "pairwise_results_df.to_csv('pairwise_wilcoxon_results.csv', index=False)\n",
    "\n",
    "# Optional: Export the DataFrames to Excel for easier viewing\n",
    "with pd.ExcelWriter('statistical_analysis_results.xlsx') as writer:\n",
    "    mean_metrics_df.to_excel(writer, sheet_name='Mean Metrics', index=False)\n",
    "    friedman_results_df.to_excel(writer, sheet_name='Friedman Test', index=False)\n",
    "    pairwise_results_df.to_excel(writer, sheet_name='Wilcoxon Tests', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868d7674-7585-41db-8373-98c0c89ef4f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:asa]",
   "language": "python",
   "name": "conda-env-asa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
